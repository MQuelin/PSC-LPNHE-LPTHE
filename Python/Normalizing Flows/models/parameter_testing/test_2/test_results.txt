Testing for parameter influence on model efficiency


training on 100k2.pkl
espilon = 0.05, lr = 0.0005, batch_size= 1000, train/test ratio : 0.8

parameters explorered :

layer_counts : [16, 32, 64]
MLP_shape_lists : [[80, 80], [160, 160], [320, 320], [160, 160, 160], [80, 80, 80, 80], [60, 60, 60, 60, 60, 60]]


____________________________________________________
CNF_16lyrs_2x80shape_100k2Zee_0.05_060324.pt
trained for 30 epochs

model index : i=0

final loss = 0.10612030327320099

training loss exerpt (in steps of 20 to reduce amount of data displayed) :
[0.8793129324913025, 0.23301343619823456, 0.19758941233158112, 0.16685590147972107, 0.1463422030210495, 0.13758431375026703, 0.13598255813121796, 0.13155709207057953, 0.12842796742916107, 0.11647044867277145, 0.12402530014514923, 0.10980039089918137, 0.10966745764017105, 0.11302097886800766, 0.10945546627044678, 0.115145742893219, 0.1107911691069603, 0.11346399784088135, 0.10859914124011993, 0.10863502323627472, 0.10420802980661392, 0.11194860935211182, 0.10779136419296265, 0.10655710846185684, 0.1079743504524231, 0.11078450828790665, 0.10666104406118393, 0.11198951303958893, 0.10970558971166611, 0.10950382053852081]

testing loss exerpt (in steps of 5 to reduce amount of data displayed) :
[0.23439152538776398, 0.19025051593780518, 0.16004621982574463, 0.14521965384483337, 0.13938848674297333, 0.13649067282676697, 0.1307123899459839, 0.12349613010883331, 0.12119070440530777, 0.12051787227392197, 0.12349587678909302, 0.11560537666082382, 0.11793725937604904, 0.1083684116601944, 0.10889174789190292, 0.11215846985578537, 0.11259597539901733, 0.1100270077586174, 0.11654575914144516, 0.11081402748823166, 0.11121553182601929, 0.11175129562616348, 0.1124730259180069, 0.10804281383752823, 0.10926419496536255, 0.10695362091064453, 0.10563372820615768, 0.10697291046380997, 0.10675451904535294, 0.112592414021492]

____________________________________________________
CNF_16lyrs_2x160shape_100k2Zee_0.05_060324.pt
trained for 30 epochs

model index : i=1

final loss = 0.28957295417785645

training loss exerpt (in steps of 20 to reduce amount of data displayed) :
[0.8460332751274109, 0.18477466702461243, 0.14253340661525726, 0.1420770138502121, 0.12589530646800995, 0.12335439771413803, 0.12090957164764404, 0.11771263182163239, 0.1150866150856018, 0.11781549453735352, 0.11686374992132187, 0.10917752236127853, 0.11360696703195572, 0.10681678354740143, 0.1106356754899025, 0.11409655958414078, 0.11079192161560059, 0.10911788046360016, 0.10463722050189972, 0.10840010643005371, 0.10691797733306885, 0.10666918754577637, 0.10883907228708267, 0.10824575275182724, 0.10725022852420807, 0.1049819141626358, 0.10041435807943344, 0.10557865351438522, 0.10468845814466476, 0.10569404810667038]

testing loss exerpt (in steps of 5 to reduce amount of data displayed) :
[0.1906929314136505, 0.14231714606285095, 0.132368266582489, 0.12683026492595673, 0.12471294403076172, 0.1307632178068161, 0.11842051893472672, 0.11851146072149277, 0.11333175003528595, 0.11797808855772018, 0.11793410778045654, 0.11420973390340805, 0.23562732338905334, 0.23824737966060638, 0.10972956568002701, 0.10891248285770416, 0.1080813929438591, 0.23769621551036835, 0.11106254160404205, 0.10847920179367065, 0.10770191252231598, 0.1113908663392067, 0.11250567436218262, 0.10763845592737198, 0.2578332722187042, 0.25765371322631836, 0.10463900864124298, 0.10995189100503922, 0.10838432610034943, 0.11164496093988419]

____________________________________________________
CNF_16lyrs_2x320shape_100k2Zee_0.05_060324.pt
trained for 30 epochs

model index : i=2

final loss = 0.12104018777608871

training loss exerpt (in steps of 20 to reduce amount of data displayed) :
[0.793776273727417, 0.17301411926746368, 0.15716849267482758, 0.14013458788394928, 0.14327676594257355, 0.14986206591129303, 0.14709584414958954, 0.13768208026885986, 0.13658210635185242, 0.12764327228069305, 0.1289496272802353, 0.1307864785194397, 0.12960641086101532, 0.12457423657178879, 0.12599101662635803, 0.12598298490047455, 0.12349307537078857, 0.12094231694936752, 0.1288260668516159, 0.12472299486398697, 0.1207238957285881, 0.12110584229230881, 0.12409039586782455, 0.12383746355772018, 0.11889920383691788, 0.1268552839756012, 0.12437427043914795, 0.1199040561914444, 0.1213562861084938, 0.12163879722356796]

testing loss exerpt (in steps of 5 to reduce amount of data displayed) :
[0.16890941560268402, 0.14322905242443085, 0.1367180496454239, 0.1382889598608017, 0.14248637855052948, 0.13940124213695526, 0.12919729948043823, 0.13293138146400452, 0.12186764925718307, 0.12172066420316696, 0.12931039929389954, 0.12102507799863815, 0.11967169493436813, 0.1256304830312729, 0.11952195316553116, 0.12206462770700455, 0.11815567314624786, 0.11879327148199081, 0.11611884832382202, 0.12258601188659668, 0.11842431128025055, 0.12020479887723923, 0.12036514282226562, 0.12237989157438278, 0.11970525979995728, 0.1130281314253807, 0.11704301089048386, 0.11816787719726562, 0.11258363723754883, 0.11893295496702194]

____________________________________________________
CNF_16lyrs_3x160shape_100k2Zee_0.05_060324.pt
trained for 30 epochs

model index : i=3

final loss = 0.10910288244485855

training loss exerpt (in steps of 20 to reduce amount of data displayed) :
[0.6159316897392273, 0.1905473917722702, 0.15261544287204742, 0.14329929649829865, 0.1335139125585556, 0.12722709774971008, 0.12521326541900635, 0.12173619121313095, 0.11714889854192734, 0.11496713012456894, 0.11129876226186752, 0.11017631739377975, 0.11732138693332672, 0.11351113766431808, 0.11266481876373291, 0.10801535844802856, 0.11076059192419052, 0.11237204074859619, 0.10545574873685837, 0.10943680256605148, 0.11398005485534668, 0.10936921834945679, 0.10642415285110474, 0.1085929274559021, 0.10839887708425522, 0.10437134653329849, 0.10698550939559937, 0.10474121570587158, 0.11027920246124268, 0.10888021439313889]

testing loss exerpt (in steps of 5 to reduce amount of data displayed) :
[0.19818271696567535, 0.1499333679676056, 0.14212462306022644, 0.1402612328529358, 0.12484663724899292, 0.12722262740135193, 0.12670360505580902, 0.11802945286035538, 0.1185484305024147, 0.11268015950918198, 0.10983266681432724, 0.10867120325565338, 0.1145910993218422, 0.10862983763217926, 0.10612154006958008, 0.11334890127182007, 0.11307060718536377, 0.10466374456882477, 0.1088225468993187, 0.11224565654993057, 0.10856304317712784, 0.10813814401626587, 0.10838544368743896, 0.10979515314102173, 0.11025232076644897, 0.10416153818368912, 0.10897386074066162, 0.1098594069480896, 0.10890388488769531, 0.10317432135343552]

____________________________________________________
CNF_16lyrs_4x80shape_100k2Zee_0.05_060324.pt
trained for 30 epochs

model index : i=4

final loss = 0.10867568105459213

training loss exerpt (in steps of 20 to reduce amount of data displayed) :
[0.6373624205589294, 0.23889732360839844, 0.20727351307868958, 0.17942677438259125, 0.15194390714168549, 0.14082549512386322, 0.1355116218328476, 0.11794029921293259, 0.12365283071994781, 0.11308185011148453, 0.11469525098800659, 0.10909449309110641, 0.11107993125915527, 0.1070047989487648, 0.11211284250020981, 0.11259651184082031, 0.10342877358198166, 0.10871592909097672, 0.10320701450109482, 0.1107286736369133, 0.11136534065008163, 0.1121518611907959, 0.10354526340961456, 0.10465359687805176, 0.10539846867322922, 0.10514918714761734, 0.10560610145330429, 0.10062942653894424, 0.11250732094049454, 0.10614906996488571]

testing loss exerpt (in steps of 5 to reduce amount of data displayed) :
[0.22051207721233368, 0.19926272332668304, 0.17363496124744415, 0.15213552117347717, 0.14483414590358734, 0.13996407389640808, 0.12193433195352554, 0.12176584452390671, 0.11028774827718735, 0.11426018923521042, 0.10942784696817398, 0.11305365711450577, 0.10978212207555771, 0.10621105879545212, 0.11051050573587418, 0.11105912923812866, 0.11270984262228012, 0.10796079784631729, 0.10854333639144897, 0.10490363836288452, 0.1112842783331871, 0.10860361903905869, 0.1101941242814064, 0.10497396439313889, 0.10405003279447556, 0.10558757930994034, 0.10410075634717941, 0.10512292385101318, 0.10894775390625, 0.10598427057266235]

____________________________________________________
CNF_16lyrs_6x60shape_100k2Zee_0.05_060324.pt
trained for 30 epochs

model index : i=5

final loss = 0.11476045846939087

training loss exerpt (in steps of 20 to reduce amount of data displayed) :
[0.6967014074325562, 0.3360837399959564, 0.26490041613578796, 0.224237322807312, 0.19048070907592773, 0.1736806482076645, 0.16370902955532074, 0.15052738785743713, 0.145713210105896, 0.1396411657333374, 0.13096407055854797, 0.14028136432170868, 0.13207247853279114, 0.12612229585647583, 0.12380508333444595, 0.11908221244812012, 0.12000399082899094, 0.11819543689489365, 0.12428801506757736, 0.11911683529615402, 0.11505474150180817, 0.11661692708730698, 0.11799540370702744, 0.11247452348470688, 0.11668612062931061, 0.11444360017776489, 0.12038319557905197, 0.11540130525827408, 0.11628972738981247, 0.11477910727262497]

testing loss exerpt (in steps of 5 to reduce amount of data displayed) :
[0.33055850863456726, 0.2719361186027527, 0.22237522900104523, 0.18351465463638306, 0.16803960502147675, 0.16681839525699615, 0.15929482877254486, 0.14128853380680084, 0.1393168419599533, 0.13534270226955414, 0.1435822695493698, 0.12791678309440613, 0.11612290143966675, 0.12892015278339386, 0.1170109286904335, 0.11908997595310211, 0.12076052278280258, 0.1287735104560852, 0.11930737644433975, 0.12075406312942505, 0.1227380633354187, 0.11081843823194504, 0.1142534390091896, 0.11594656854867935, 0.11773967742919922, 0.11353778094053268, 0.11807277053594589, 0.1126936599612236, 0.11436008661985397, 0.11284808069467545]

____________________________________________________
CNF_32lyrs_2x80shape_100k2Zee_0.05_060324.pt
trained for 30 epochs

model index : i=6

final loss = 0.10117819160223007

training loss exerpt (in steps of 20 to reduce amount of data displayed) :
[1.563571810722351, 0.23219533264636993, 0.18725505471229553, 0.16136986017227173, 0.15612713992595673, 0.139718160033226, 0.13081315159797668, 0.12065251916646957, 0.12849359214305878, 0.12298443168401718, 0.12003111094236374, 0.11414787918329239, 0.11270105093717575, 0.11676760762929916, 0.10927903652191162, 0.10940474271774292, 0.10903608798980713, 0.10847193002700806, 0.10697406530380249, 0.10546431690454483, 0.10747605562210083, 0.10958508402109146, 0.1048642173409462, 0.10499818623065948, 0.105756476521492, 0.10564922541379929, 0.10677485913038254, 0.10625002533197403, 0.10866308212280273, 0.10718108713626862]

testing loss exerpt (in steps of 5 to reduce amount of data displayed) :
[0.23192636668682098, 0.17702935636043549, 0.16133663058280945, 0.1446782648563385, 0.13697560131549835, 0.12920436263084412, 0.1252061426639557, 0.12868475914001465, 0.11719508469104767, 0.11950496584177017, 0.11695735901594162, 0.11096253246068954, 0.11407412588596344, 0.10999864339828491, 0.11064734309911728, 0.10651236772537231, 0.11142142862081528, 0.10579434782266617, 0.10738015174865723, 0.10160918533802032, 0.11151031404733658, 0.10877136141061783, 0.10311853140592575, 0.1030094251036644, 0.10099726915359497, 0.10021726042032242, 0.10374712198972702, 0.1011665016412735, 0.10549229383468628, 0.10815709084272385]

____________________________________________________
CNF_32lyrs_2x160shape_100k2Zee_0.05_060324.pt
trained for 30 epochs

model index : i=7

final loss = 0.10581216961145401

training loss exerpt (in steps of 20 to reduce amount of data displayed) :
[1.5755914449691772, 0.19340752065181732, 0.15408943593502045, 0.14790977537631989, 0.13383708894252777, 0.12432119995355606, 0.12651881575584412, 0.12056924402713776, 0.12050382047891617, 0.11635173857212067, 0.12674149870872498, 0.1232835054397583, 0.11762160062789917, 0.12098715454339981, 0.12235353142023087, 0.12322439253330231, 0.11835791915655136, 0.11808055639266968, 0.11422932147979736, 0.11879239231348038, 0.11260179430246353, 0.10535849630832672, 0.10738223046064377, 0.10360677540302277, 0.10602716356515884, 0.10608094185590744, 0.11168364435434341, 0.10566369444131851, 0.10633067041635513, 0.10135409981012344]

testing loss exerpt (in steps of 5 to reduce amount of data displayed) :
[0.19334886968135834, 0.16264505684375763, 0.14451000094413757, 0.14050935208797455, 0.12975822389125824, 0.12875883281230927, 0.12722021341323853, 0.1278855800628662, 0.1232825443148613, 0.12026554346084595, 0.12694673240184784, 0.12464964389801025, 0.12236984074115753, 0.11831414699554443, 0.12266359478235245, 0.12525247037410736, 0.12164266407489777, 0.12225170433521271, 0.11604122072458267, 0.1109221950173378, 0.108542799949646, 0.10583750158548355, 0.10775189846754074, 0.10873376578092575, 0.10837503522634506, 0.10332196950912476, 0.10429876297712326, 0.11313694715499878, 0.10625924915075302, 0.10331364721059799]

____________________________________________________
CNF_32lyrs_2x320shape_100k2Zee_0.05_060324.pt
trained for 30 epochs

model index : i=8

final loss = 0.11765947192907333

training loss exerpt (in steps of 20 to reduce amount of data displayed) :
[1.4113200902938843, 0.15984313189983368, 0.14388495683670044, 0.13881587982177734, 0.14121834933757782, 0.13747133314609528, 0.14051155745983124, 0.13087455928325653, 0.13256078958511353, 0.1342570185661316, 0.12655073404312134, 0.12619632482528687, 0.1261480152606964, 0.1328200250864029, 0.12245263159275055, 0.12665489315986633, 0.12987588346004486, 0.12468800693750381, 0.1284799426794052, 0.1362471878528595, 0.13397382199764252, 0.11987902224063873, 0.1280587911605835, 0.11570929735898972, 0.1192018911242485, 0.12187211960554123, 0.11517024040222168, 0.1228928342461586, 0.12441541254520416, 0.12071367353200912]

testing loss exerpt (in steps of 5 to reduce amount of data displayed) :
[0.1671920269727707, 0.14175137877464294, 0.14874793589115143, 0.1434517651796341, 0.1352984756231308, 0.14378492534160614, 0.12788046896457672, 0.1307789534330368, 0.1273277848958969, 0.13459070026874542, 0.12482630461454391, 0.12323691695928574, 0.1289392113685608, 0.12523286044597626, 0.12845735251903534, 0.12818817794322968, 0.12579594552516937, 0.1283196657896042, 0.1277281790971756, 0.1296168565750122, 0.11973710358142853, 0.12039133161306381, 0.12005510181188583, 0.12132225185632706, 0.11992000788450241, 0.12103606760501862, 0.1211785227060318, 0.12439890950918198, 0.12191802263259888, 0.12344975769519806]

____________________________________________________
CNF_32lyrs_3x160shape_100k2Zee_0.05_060324.pt
trained for 30 epochs

model index : i=9

final loss = 0.10755165666341782

training loss exerpt (in steps of 20 to reduce amount of data displayed) :
[0.9687514305114746, 0.18431387841701508, 0.1323203444480896, 0.1337529867887497, 0.1272401511669159, 0.127949520945549, 0.12011293321847916, 0.10875441879034042, 0.11246123164892197, 0.11070059984922409, 0.1094171330332756, 0.11090266704559326, 0.10844609886407852, 0.10968603938817978, 0.10395149141550064, 0.1068001538515091, 0.10178947448730469, 0.10463815927505493, 0.10555869340896606, 0.10180244594812393, 0.11045517772436142, 0.10397499799728394, 0.10405004024505615, 0.10545586794614792, 0.10336872190237045, 0.1032332330942154, 0.10829388350248337, 0.10126036405563354, 0.10165172815322876, 0.10711170732975006]

testing loss exerpt (in steps of 5 to reduce amount of data displayed) :
[0.17158877849578857, 0.14446298778057098, 0.13069580495357513, 0.12947948276996613, 0.12619122862815857, 0.12381263077259064, 0.10993806272745132, 0.10876859724521637, 0.10939278453588486, 0.10897459089756012, 0.10427545756101608, 0.105292908847332, 0.10287437587976456, 0.11012772470712662, 0.10144264996051788, 0.10558240860700607, 0.10376675426959991, 0.11226927489042282, 0.10305581241846085, 0.10262072086334229, 0.10452412813901901, 0.10404044389724731, 0.10221395641565323, 0.1035546213388443, 0.1050574779510498, 0.10475649684667587, 0.10351765155792236, 0.10417808592319489, 0.10315761715173721, 0.10512538999319077]

____________________________________________________
CNF_32lyrs_4x80shape_100k2Zee_0.05_060324.pt
trained for 30 epochs

model index : i=10

final loss = 0.11661449819803238

training loss exerpt (in steps of 20 to reduce amount of data displayed) :
[1.2192620038986206, 0.2659315764904022, 0.1968148797750473, 0.16256992518901825, 0.1428624838590622, 0.15097419917583466, 0.12719571590423584, 0.12982819974422455, 0.12392186373472214, 0.11771734058856964, 0.14510129392147064, 0.11956451088190079, 0.11877629905939102, 0.12052623182535172, 0.1198730394244194, 0.11628159135580063, 0.11536777019500732, 0.11749190092086792, 0.10965128242969513, 0.11603035032749176, 0.11948287487030029, 0.11395087093114853, 0.11123465746641159, 0.11453855037689209, 0.11565496027469635, 0.11798740923404694, 0.11568138748407364, 0.11250102519989014, 0.11551594734191895, 0.11854834854602814]

testing loss exerpt (in steps of 5 to reduce amount of data displayed) :
[0.26392069458961487, 0.1883605718612671, 0.1551165133714676, 0.15897659957408905, 0.14913824200630188, 0.1348116248846054, 0.1277645379304886, 0.1231892928481102, 0.12655405700206757, 0.12256014347076416, 0.11601042747497559, 0.11411551386117935, 0.11917497962713242, 0.1215594932436943, 0.12319361418485641, 0.11766063421964645, 0.11494334787130356, 0.12464263290166855, 0.11942503601312637, 0.11835654824972153, 0.11714919656515121, 0.1205228939652443, 0.11249935626983643, 0.11188512295484543, 0.11766482889652252, 0.11292511224746704, 0.11861854046583176, 0.11482971906661987, 0.11639881134033203, 0.11509259045124054]

____________________________________________________
CNF_32lyrs_6x60shape_100k2Zee_0.05_060324.pt
trained for 30 epochs

model index : i=11

final loss = 0.10818668454885483

training loss exerpt (in steps of 20 to reduce amount of data displayed) :
[1.3205102682113647, 0.35884690284729004, 0.29404282569885254, 0.24362681806087494, 0.19355149567127228, 0.17077700793743134, 0.14922142028808594, 0.13649986684322357, 0.1331399381160736, 0.1287325769662857, 0.11748210340738297, 0.12122821062803268, 0.11721035093069077, 0.11819442361593246, 0.10869910567998886, 0.11127030104398727, 0.11423220485448837, 0.11520613729953766, 0.11203622072935104, 0.10953246802091599, 0.11679034680128098, 0.1067851334810257, 0.10823186486959457, 0.11678308248519897, 0.11443384736776352, 0.11416701227426529, 0.11479544639587402, 0.10790657252073288, 0.1086161658167839, 0.11788518726825714]

testing loss exerpt (in steps of 5 to reduce amount of data displayed) :
[0.36785686016082764, 0.2836609184741974, 0.22467803955078125, 0.19436629116535187, 0.17568911612033844, 0.14090825617313385, 0.13478995859622955, 0.13239102065563202, 0.12568260729312897, 0.12475547939538956, 0.11805839836597443, 0.11603254079818726, 0.11342491209506989, 0.11040966957807541, 0.11578194051980972, 0.11182200908660889, 0.11318271607160568, 0.11172693222761154, 0.11243801563978195, 0.10997171700000763, 0.1081441268324852, 0.11182548105716705, 0.11076907068490982, 0.1120682880282402, 0.10634718090295792, 0.1084052324295044, 0.1095467135310173, 0.10570138692855835, 0.11256793886423111, 0.10243654251098633]

____________________________________________________
CNF_64lyrs_2x80shape_100k2Zee_0.05_060324.pt
trained for 30 epochs

model index : i=12

final loss = 0.10700146108865738

training loss exerpt (in steps of 20 to reduce amount of data displayed) :
[3.2551934719085693, 0.22286108136177063, 0.17706601321697235, 0.1548464149236679, 0.1297561526298523, 0.12641872465610504, 0.12562823295593262, 0.12126856297254562, 0.11681798845529556, 0.11221658438444138, 0.11726834625005722, 0.11050619930028915, 0.1107478067278862, 0.1073220893740654, 0.11092803627252579, 0.1103726178407669, 0.10822786390781403, 0.10897227376699448, 0.10778247565031052, 0.1000024825334549, 0.1073884591460228, 0.10204090178012848, 0.10539194196462631, 0.10299520939588547, 0.1029248833656311, 0.10475336760282516, 0.11269344389438629, 0.10941527038812637, 0.10208509117364883, 0.10416536778211594]

testing loss exerpt (in steps of 5 to reduce amount of data displayed) :
[0.23200607299804688, 0.1664014607667923, 0.14435088634490967, 0.13764925301074982, 0.12292066961526871, 0.11488237231969833, 0.11748484522104263, 0.11277599632740021, 0.10899658501148224, 0.11091496795415878, 0.10889583081007004, 0.10866750776767731, 0.11100959032773972, 0.10834234207868576, 0.1066557914018631, 0.1115700751543045, 0.10348879545927048, 0.10704874247312546, 0.10232073068618774, 0.10872899740934372, 0.10653998702764511, 0.10410875082015991, 0.10346399992704391, 0.10434373468160629, 0.10560192167758942, 0.10750345140695572, 0.1088370680809021, 0.10182501375675201, 0.10569170862436295, 0.10471715033054352]

____________________________________________________
CNF_64lyrs_2x160shape_100k2Zee_0.05_060324.pt
trained for 30 epochs

model index : i=13

final loss = 0.44665223360061646

training loss exerpt (in steps of 20 to reduce amount of data displayed) :
[3.091012716293335, 0.20376665890216827, 0.15057557821273804, 0.12156301736831665, 0.12153255194425583, 0.11706063896417618, 0.11572927236557007, 0.11132673174142838, 0.10701324045658112, 0.11001807451248169, 0.10817179828882217, 0.10672684013843536, 0.10903902351856232, 0.10484504699707031, 0.10828262567520142, 0.10676836967468262, 0.11082176119089127, 0.10921768099069595, 0.11014234274625778, 0.1051352396607399, 0.10519448667764664, 0.10719867050647736, 0.10538321733474731, 0.10208350419998169, 0.10431469976902008, 0.1052870899438858, 0.10150454193353653, 0.10455405712127686, 0.10457169264554977, 0.10778098553419113]

testing loss exerpt (in steps of 5 to reduce amount of data displayed) :
[0.19059336185455322, 0.16951973736286163, 0.32807424664497375, 0.11675696820020676, 0.11596627533435822, 0.251824289560318, 0.1133628636598587, 0.10733940452337265, 0.11478760093450546, 0.11215434223413467, 0.11183955520391464, 0.10596483200788498, 0.10815825313329697, 0.2895079255104065, 0.10618152469396591, 0.10891047865152359, 0.30394765734672546, 0.10932576656341553, 0.10707751661539078, 0.10450464487075806, 0.3290952146053314, 0.3582688271999359, 0.11175402253866196, 0.10861372947692871, 0.3526555001735687, 0.36060911417007446, 0.10667934268712997, 0.10638170689344406, 0.3816140592098236, 0.10880186408758163]

____________________________________________________
CNF_64lyrs_2x320shape_100k2Zee_0.05_060324.pt
trained for 30 epochs

model index : i=14

final loss = 0.1217089295387268

training loss exerpt (in steps of 20 to reduce amount of data displayed) :
[2.6852235794067383, 0.17082281410694122, 0.14394114911556244, 0.13266991078853607, 0.12417347729206085, 0.1216105967760086, 0.12406809628009796, 0.1287217140197754, 0.11883138865232468, 0.12054944038391113, 0.11989619582891464, 0.1187991052865982, 0.11841975897550583, 0.11736450344324112, 0.11831303685903549, 0.11601147800683975, 0.1201682910323143, 0.12141411751508713, 0.12183018028736115, 0.12482436746358871, 0.12133099138736725, 0.11777307838201523, 0.11881115287542343, 0.1166844367980957, 0.11429720371961594, 0.11996708065271378, 0.11907770484685898, 0.12334795296192169, 0.11982456594705582, 0.11363907158374786]

testing loss exerpt (in steps of 5 to reduce amount of data displayed) :
[0.16195981204509735, 0.1561354249715805, 0.13121463358402252, 0.12684203684329987, 0.1370575875043869, 0.1259753257036209, 0.12341239303350449, 0.12192585319280624, 0.11810579150915146, 0.12146172672510147, 0.12327754497528076, 0.11861219257116318, 0.11741228401660919, 0.1169903427362442, 0.11816868931055069, 0.12758056819438934, 0.11863644421100616, 0.11831020563840866, 0.11555508524179459, 0.11862291395664215, 0.1163482815027237, 0.11897766590118408, 0.12217066437005997, 0.11446865648031235, 0.12168800830841064, 0.11609144508838654, 0.11276427656412125, 0.12202753126621246, 0.11650091409683228, 0.11715056747198105]

____________________________________________________
CNF_64lyrs_3x160shape_100k2Zee_0.05_060324.pt
trained for 30 epochs

model index : i=15

final loss = 0.10315294563770294

training loss exerpt (in steps of 20 to reduce amount of data displayed) :
[1.885249376296997, 0.18146158754825592, 0.13408999145030975, 0.1240086480975151, 0.11573555320501328, 0.11094582080841064, 0.11601006984710693, 0.1092676892876625, 0.10843908786773682, 0.11034556478261948, 0.11354666203260422, 0.1069047674536705, 0.10894069820642471, 0.11163143068552017, 0.10697057098150253, 0.10785559564828873, 0.10516376793384552, 0.10222534090280533, 0.10959916561841965, 0.10497617721557617, 0.10457652807235718, 0.10788877308368683, 0.10779839754104614, 0.10304545611143112, 0.09995018690824509, 0.10586359351873398, 0.10628657788038254, 0.10361576080322266, 0.10404448956251144, 0.10385014861822128]

testing loss exerpt (in steps of 5 to reduce amount of data displayed) :
[0.19082967936992645, 0.1389397233724594, 0.1240600124001503, 0.129933699965477, 0.11877540498971939, 0.114323690533638, 0.10670987516641617, 0.11041489988565445, 0.11247789114713669, 0.10435813665390015, 0.1078442707657814, 0.1074911504983902, 0.10481416434049606, 0.11032942682504654, 0.1087886244058609, 0.10512236505746841, 0.10443582385778427, 0.11001419275999069, 0.10826011002063751, 0.10632248967885971, 0.10332834720611572, 0.10629985481500626, 0.10276304930448532, 0.10070612281560898, 0.10654425621032715, 0.10599853843450546, 0.10445034503936768, 0.10710185766220093, 0.10314270108938217, 0.10512834787368774]

____________________________________________________
CNF_64lyrs_4x80shape_100k2Zee_0.05_060324.pt
trained for 30 epochs

model index : i=16

final loss = 0.10579073429107666

training loss exerpt (in steps of 20 to reduce amount of data displayed) :
[2.1631407737731934, 0.290870726108551, 0.1923399269580841, 0.15802530944347382, 0.1350814402103424, 0.12276631593704224, 0.12571756541728973, 0.11699316650629044, 0.11104799807071686, 0.10815926641225815, 0.11103836447000504, 0.10981563478708267, 0.10252183675765991, 0.10597232729196548, 0.10723985731601715, 0.10606274753808975, 0.10699930042028427, 0.10245192050933838, 0.10208345949649811, 0.10624028742313385, 0.10711111128330231, 0.10494088381528854, 0.10558461397886276, 0.10422921180725098, 0.10763796418905258, 0.10938272625207901, 0.10304256528615952, 0.10305102914571762, 0.10416685789823532, 0.10807418823242188]

testing loss exerpt (in steps of 5 to reduce amount of data displayed) :
[0.26364538073539734, 0.1954329013824463, 0.1657080203294754, 0.1457708775997162, 0.12321089953184128, 0.11422493308782578, 0.11329000443220139, 0.11775650084018707, 0.11178844422101974, 0.1070091500878334, 0.10694575309753418, 0.11089978367090225, 0.10923200845718384, 0.11315044015645981, 0.10878527164459229, 0.10672175139188766, 0.10428859293460846, 0.10804939270019531, 0.10773225873708725, 0.10682498663663864, 0.10404161363840103, 0.10825735330581665, 0.10710226744413376, 0.10662569105625153, 0.10504509508609772, 0.10781055688858032, 0.10513567924499512, 0.10448838770389557, 0.1063382625579834, 0.10418573766946793]

____________________________________________________
CNF_64lyrs_6x60shape_100k2Zee_0.05_060324.pt
trained for 30 epochs

model index : i=17

final loss = 0.10865823179483414

training loss exerpt (in steps of 20 to reduce amount of data displayed) :
[2.5667288303375244, 0.4473729729652405, 0.27733132243156433, 0.2036021202802658, 0.1781269907951355, 0.14715828001499176, 0.13838396966457367, 0.14078593254089355, 0.11924175173044205, 0.11402130126953125, 0.11257435381412506, 0.11182534694671631, 0.10887634754180908, 0.11147600412368774, 0.1068795695900917, 0.10836277157068253, 0.10877485573291779, 0.10782714188098907, 0.10531272739171982, 0.10934527218341827, 0.10839428007602692, 0.10496946424245834, 0.10727959871292114, 0.10288102924823761, 0.10213802009820938, 0.10112861543893814, 0.10331179946660995, 0.10246048122644424, 0.10616036504507065, 0.10438287258148193]

testing loss exerpt (in steps of 5 to reduce amount of data displayed) :
[0.42016419768333435, 0.2727592885494232, 0.20028534531593323, 0.17672620713710785, 0.15258680284023285, 0.13885380327701569, 0.12925010919570923, 0.12254728376865387, 0.11747648566961288, 0.11371538788080215, 0.11750399321317673, 0.1080172210931778, 0.12875929474830627, 0.11166106909513474, 0.1343652755022049, 0.12644736468791962, 0.10613755136728287, 0.1123398095369339, 0.10532122105360031, 0.10564780235290527, 0.10679196566343307, 0.10947258770465851, 0.10289653390645981, 0.12443865835666656, 0.1041022539138794, 0.12492095679044724, 0.12634240090847015, 0.10782995074987411, 0.10381533950567245, 0.1039964109659195]

____________________________________________________

 successfuly exited full training and testing loop

final testing errors, ordered by model index :
[0.10612030327320099, 0.28957295417785645, 0.12104018777608871, 0.10910288244485855, 0.10867568105459213, 0.11476045846939087, 0.10117819160223007, 0.10581216961145401, 0.11765947192907333, 0.10755165666341782, 0.11661449819803238, 0.10818668454885483, 0.10700146108865738, 0.44665223360061646, 0.1217089295387268, 0.10315294563770294, 0.10579073429107666, 0.10865823179483414]

minimal error reached for model of index i=13