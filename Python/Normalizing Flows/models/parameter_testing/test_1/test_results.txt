Testing for parameter influence on model efficiency


training on 100k2.pkl
espilon = 0.05, lr = 0.0005, batch_size= 1000, train/test ratio : 0.8

parameters explorered :

layer_counts : [4, 8, 16, 32, 64, 128, 256, 512]
MLP_shape_lists : [[10, 10], [20, 20], [40, 40], [80, 80], [10, 10, 10], [80, 80, 80], [20, 20, 20, 20]]


____________________________________________________
CNF_4lyrs_10_10_shape_100k2Zee_0.05_060324.pt
trained for 20 epochs

index : 0

final loss = 0.19563519954681396

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[0.6632810831069946, 0.5300162434577942, 0.5086235404014587, 0.46410033106803894, 0.4771902561187744, 0.4325908124446869, 0.40540122985839844, 0.5016701221466064, 0.37556174397468567, 0.357295423746109, 0.44245290756225586, 0.35318639874458313, 0.4403984248638153, 0.29809123277664185, 0.33047398924827576, 0.3095960319042206, 0.4513947665691376, 0.2906056344509125, 0.26405569911003113, 0.27666139602661133, 0.29966381192207336, 0.25635167956352234, 0.24579405784606934, 0.2423841804265976, 0.24274611473083496, 0.24237428605556488, 0.24878552556037903, 0.23636534810066223, 0.21858273446559906, 0.22046402096748352, 0.21087995171546936, 0.21164901554584503, 0.22193625569343567, 0.22100985050201416, 0.19825953245162964, 0.21766579151153564, 0.20557864010334015, 0.18810980021953583, 0.19183115661144257, 0.19927792251110077]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[0.5206478238105774, 0.5078865885734558, 0.46690914034843445, 0.4490043818950653, 0.401442289352417, 0.3771344721317291, 0.3877142667770386, 0.36527714133262634, 0.3434596359729767, 0.3180564343929291, 0.31616148352622986, 0.3095201551914215, 0.28906163573265076, 0.3133930265903473, 0.30128583312034607, 0.2550412118434906, 0.2652622163295746, 0.2532469630241394, 0.2822932302951813, 0.24384573101997375, 0.23532047867774963, 0.2240968495607376, 0.22125022113323212, 0.25121065974235535, 0.22783039510250092, 0.20676986873149872, 0.2280038595199585, 0.22149372100830078, 0.20324759185314178, 0.2032928466796875, 0.2011072188615799, 0.19550016522407532, 0.19493983685970306, 0.19563519954681396]

____________________________________________________
CNF_4lyrs_20_20_shape_100k2Zee_0.05_060324.pt
trained for 20 epochs

index : 1

final loss = 0.16536399722099304

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[0.4755733907222748, 0.4016185700893402, 0.36147356033325195, 0.349349707365036, 0.31098052859306335, 0.3116605281829834, 0.2560235559940338, 0.2523361146450043, 0.263054758310318, 0.23931534588336945, 0.2358226329088211, 0.20814736187458038, 0.23098258674144745, 0.3948799967765808, 0.2155187427997589, 0.21756644546985626, 0.38779589533805847, 0.2251056283712387, 0.22572600841522217, 0.20121383666992188, 0.20623715221881866, 0.2122766226530075, 0.20932817459106445, 0.18650367856025696, 0.1939658373594284, 0.1797734797000885, 0.17939242720603943, 0.17674921452999115, 0.17502819001674652, 0.1791740357875824, 0.1735127866268158, 0.16879180073738098, 0.16640101373195648, 0.1749534159898758, 0.15986427664756775, 0.15606987476348877, 0.2789911925792694, 0.1545533835887909, 0.15585248172283173, 0.1501445472240448]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[0.3686264753341675, 0.35412201285362244, 0.320015013217926, 0.29757335782051086, 0.28035473823547363, 0.2730012536048889, 0.24837306141853333, 0.2496858388185501, 0.25687363743782043, 0.22985069453716278, 0.21278102695941925, 0.2567687928676605, 0.22990186512470245, 0.27709516882896423, 0.21490101516246796, 0.19681786000728607, 0.20923693478107452, 0.20168538391590118, 0.18791666626930237, 0.1876082569360733, 0.18898020684719086, 0.1784123033285141, 0.19398264586925507, 0.18047693371772766, 0.1768505722284317, 0.17445780336856842, 0.1640012562274933, 0.167343407869339, 0.16883717477321625, 0.17319561541080475, 0.15502768754959106, 0.16312143206596375, 0.15708594024181366, 0.16536399722099304]

____________________________________________________
CNF_4lyrs_40_40_shape_100k2Zee_0.05_060324.pt
trained for 20 epochs

index : 2

final loss = 0.13069355487823486

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[0.4748326241970062, 0.5404161214828491, 0.2961996793746948, 0.3585301339626312, 0.29059919714927673, 0.22901470959186554, 0.21806955337524414, 0.21117277443408966, 0.2051691859960556, 0.22444914281368256, 0.20169959962368011, 0.20005081593990326, 0.18520647287368774, 0.17349806427955627, 0.16805113852024078, 0.1774231642484665, 0.17363886535167694, 0.16654124855995178, 0.17389194667339325, 0.15901219844818115, 0.1607411652803421, 0.15279527008533478, 0.1533801406621933, 0.1442960947751999, 0.14693760871887207, 0.15240944921970367, 0.13861195743083954, 0.14026755094528198, 0.13978777825832367, 0.1369393914937973, 0.1362805813550949, 0.13634100556373596, 0.1331234723329544, 0.12884949147701263, 0.12889020144939423, 0.1361846774816513, 0.12868240475654602, 0.13085582852363586, 0.12287936359643936, 0.13024455308914185]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[0.28730225563049316, 0.2954957187175751, 0.23665836453437805, 0.260387659072876, 0.5402767658233643, 0.2113523930311203, 0.22015154361724854, 0.21885152161121368, 0.19444948434829712, 0.1888536661863327, 0.17418578267097473, 0.17770884931087494, 0.17020882666110992, 0.46820059418678284, 0.16378028690814972, 0.37181562185287476, 0.14933021366596222, 0.15358661115169525, 0.15190452337265015, 0.33584654331207275, 0.14894017577171326, 0.1410800963640213, 0.3340996503829956, 0.14256209135055542, 0.13389787077903748, 0.1379551738500595, 0.13665859401226044, 0.32541605830192566, 0.13445861637592316, 0.1321401745080948, 0.13186119496822357, 0.13172350823879242, 0.1299086958169937, 0.13069355487823486]

____________________________________________________
CNF_4lyrs_80_80_shape_100k2Zee_0.05_060324.pt
trained for 20 epochs

index : 3

final loss = 0.11691804230213165

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[0.4144754111766815, 0.2923876643180847, 0.2394331991672516, 0.2200871706008911, 0.21811221539974213, 0.4967684745788574, 0.187432199716568, 0.18617282807826996, 0.17265735566616058, 0.16299842298030853, 0.1520288735628128, 0.16037294268608093, 0.14666780829429626, 0.14232990145683289, 0.13983257114887238, 0.13732865452766418, 0.13074438273906708, 0.1286035031080246, 0.1286814957857132, 0.12650884687900543, 0.1253095269203186, 0.11942791193723679, 0.12352441996335983, 0.11786234378814697, 0.13058136403560638, 0.11808954924345016, 0.12392496317625046, 0.11917060613632202, 0.11905451864004135, 0.11334868520498276, 0.11996559053659439, 0.12084878981113434, 0.11853059381246567, 0.12149059027433395, 0.11458127945661545, 0.11719895899295807, 0.11958247423171997, 0.11357640475034714, 0.11680791527032852, 0.11758247762918472]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[0.22553062438964844, 0.24730268120765686, 0.20496368408203125, 0.2115342617034912, 0.18836182355880737, 0.1656021922826767, 0.17948421835899353, 0.15928904712200165, 0.15240360796451569, 0.1473163366317749, 0.14059209823608398, 0.1375861018896103, 0.13326385617256165, 0.14024411141872406, 0.12849470973014832, 0.11672329157590866, 0.12881766259670258, 0.1217193603515625, 0.12397189438343048, 0.12328040599822998, 0.11440692096948624, 0.11958415806293488, 0.11413752287626266, 0.12176797538995743, 0.11445062607526779, 0.11499800533056259, 0.11924105137586594, 0.11650889366865158, 0.1151868924498558, 0.11768084764480591, 0.11530367285013199, 0.11521106958389282, 0.11231036484241486, 0.11691804230213165]

____________________________________________________
CNF_4lyrs_10_10_10_shape_100k2Zee_0.05_060324.pt
trained for 20 epochs

index : 4

final loss = 0.19735847413539886

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[0.5801796317100525, 0.5685701370239258, 0.5402598977088928, 0.5400499701499939, 0.5050229430198669, 0.4915992319583893, 0.4325385093688965, 0.6041975021362305, 0.4395514130592346, 0.387064129114151, 0.38668888807296753, 0.3554592430591583, 0.3407347798347473, 0.35410076379776, 0.3217507004737854, 0.34259411692619324, 0.3192432224750519, 0.4127502143383026, 0.3055724799633026, 0.27298396825790405, 0.28656071424484253, 0.26738879084587097, 0.25656232237815857, 0.27238771319389343, 0.2588787376880646, 0.2641352415084839, 0.2430582493543625, 0.22472472488880157, 0.28677046298980713, 0.4026006758213043, 0.23672881722450256, 0.35425809025764465, 0.2269018441438675, 0.22935064136981964, 0.206735759973526, 0.24935631453990936, 0.21921861171722412, 0.2302357405424118, 0.2161846160888672, 0.2248002141714096]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[0.529802680015564, 0.5433743596076965, 0.48628589510917664, 0.49519678950309753, 0.443826287984848, 0.42672163248062134, 0.40754586458206177, 0.36575865745544434, 0.390259712934494, 0.34465155005455017, 0.3327593505382538, 0.34006398916244507, 0.33212003111839294, 0.2945041358470917, 0.2941020429134369, 0.28364691138267517, 0.28325700759887695, 0.2685193717479706, 0.26526522636413574, 0.2392200082540512, 0.2470412701368332, 0.24262316524982452, 0.24477891623973846, 0.26275208592414856, 0.24427472054958344, 0.2371435910463333, 0.2287752628326416, 0.21969063580036163, 0.22512049973011017, 0.23431169986724854, 0.2140190601348877, 0.21305184066295624, 0.21866479516029358, 0.19735847413539886]

____________________________________________________
CNF_4lyrs_80_80_80_shape_100k2Zee_0.05_060324.pt
trained for 20 epochs

index : 5

final loss = 0.11389028280973434

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[0.367582768201828, 0.2944428622722626, 0.25655582547187805, 0.2441684454679489, 0.2178029865026474, 0.20866064727306366, 0.20023460686206818, 0.18111346662044525, 0.18340754508972168, 0.18123970925807953, 0.1582818478345871, 0.16025178134441376, 0.15171480178833008, 0.16469958424568176, 0.14249129593372345, 0.14483216404914856, 0.14396700263023376, 0.1454104632139206, 0.13038988411426544, 0.12440287321805954, 0.12650369107723236, 0.11388955265283585, 0.11717400699853897, 0.12218467146158218, 0.12175369262695312, 0.1206057220697403, 0.12262051552534103, 0.12161300331354141, 0.12126898020505905, 0.1162366271018982, 0.11013428121805191, 0.11855568736791611, 0.11489468812942505, 0.1130126342177391, 0.11438701301813126, 0.1159248873591423, 0.11498673260211945, 0.11500269174575806, 0.11573562771081924, 0.11475371569395065]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[0.23874512314796448, 0.3997749388217926, 0.21217213571071625, 0.2036481648683548, 0.19977453351020813, 0.18846391141414642, 0.1770799607038498, 0.15472252666950226, 0.16838334500789642, 0.15626409649848938, 0.1480393260717392, 0.14074581861495972, 0.13890230655670166, 0.17966942489147186, 0.13365238904953003, 0.11658318340778351, 0.12474332004785538, 0.12402462214231491, 0.12020589411258698, 0.12572114169597626, 0.11338689178228378, 0.11662451177835464, 0.12035020440816879, 0.11924954503774643, 0.12317007035017014, 0.11263430118560791, 0.1202993169426918, 0.10848242044448853, 0.11549261957406998, 0.11291275173425674, 0.1135457381606102, 0.11460684984922409, 0.11389996111392975, 0.11389028280973434]

____________________________________________________
CNF_4lyrs_20_20_20_20_shape_100k2Zee_0.05_060324.pt
trained for 20 epochs

index : 6

final loss = 0.1856699436903

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[0.40774235129356384, 0.38626182079315186, 0.36594995856285095, 0.3338683843612671, 0.5295525789260864, 0.3181169033050537, 0.32364386320114136, 0.5202426910400391, 0.30532106757164, 0.2680160105228424, 0.28957635164260864, 0.2662172019481659, 0.26227280497550964, 0.24787814915180206, 0.2694246768951416, 0.24204204976558685, 0.36172762513160706, 0.23046059906482697, 0.24589820206165314, 0.21709740161895752, 0.2209925651550293, 0.23411038517951965, 0.22329142689704895, 0.23397016525268555, 0.21246711909770966, 0.2214798927307129, 0.20041660964488983, 0.20786407589912415, 0.2131260484457016, 0.20806021988391876, 0.2011524885892868, 0.2041393518447876, 0.19728516042232513, 0.19294749200344086, 0.19668565690517426, 0.2047000378370285, 0.18741746246814728, 0.190494105219841, 0.1856786459684372, 0.18257059156894684]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[0.40365782380104065, 0.3959272801876068, 0.32519933581352234, 0.3505063056945801, 0.3029559552669525, 0.29863640666007996, 0.3117644786834717, 0.2672693431377411, 0.31603166460990906, 0.276282399892807, 0.29801732301712036, 0.2635441720485687, 0.25318285822868347, 0.2831864356994629, 0.25516316294670105, 0.23084063827991486, 0.24946747720241547, 0.22443366050720215, 0.2341574877500534, 0.22414498031139374, 0.2051636278629303, 0.23776128888130188, 0.21801090240478516, 0.21456924080848694, 0.2005375176668167, 0.20240576565265656, 0.19734588265419006, 0.19041261076927185, 0.2012758105993271, 0.19385626912117004, 0.1846463978290558, 0.18847517669200897, 0.17567679286003113, 0.1856699436903]

____________________________________________________
CNF_8lyrs_20_20_shape_100k2Zee_0.05_060324.pt
trained for 20 epochs

final loss = 0.15046517550945282

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[0.6998984813690186, 0.5660305023193359, 0.4684777855873108, 0.41266438364982605, 0.3585361838340759, 0.33263155817985535, 0.29157325625419617, 0.26955434679985046, 0.25087764859199524, 0.23056964576244354, 0.23179380595684052, 0.25292596220970154, 0.2171171009540558, 0.2363268882036209, 0.22895853221416473, 0.20513670146465302, 0.2022259533405304, 0.18751199543476105, 0.18094183504581451, 0.19142186641693115, 0.18592044711112976, 0.17920492589473724, 0.18445701897144318, 0.18337132036685944, 0.17892813682556152, 0.16677352786064148, 0.17417584359645844, 0.16568885743618011, 0.17382779717445374, 0.16138890385627747, 0.155507430434227, 0.16412188112735748, 0.15852901339530945, 0.1524880975484848, 0.163380429148674, 0.15567542612552643, 0.15222470462322235, 0.152211531996727, 0.14562396705150604, 0.13902203738689423]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[0.4878450334072113, 0.4713272154331207, 0.36285319924354553, 0.355538934469223, 0.28060147166252136, 0.2570541799068451, 0.26324358582496643, 0.27188727259635925, 0.23139142990112305, 0.2639089822769165, 0.22269757091999054, 0.21436749398708344, 0.2133161872625351, 0.2070465385913849, 0.20360028743743896, 0.20022563636302948, 0.19203512370586395, 0.16903255879878998, 0.20281504094600677, 0.17426501214504242, 0.1783672571182251, 0.16096363961696625, 0.16441071033477783, 0.17976811528205872, 0.16082066297531128, 0.152375265955925, 0.16087765991687775, 0.1516048014163971, 0.1580670177936554, 0.14633701741695404, 0.14555346965789795, 0.14397668838500977, 0.14771632850170135, 0.15046517550945282]

____________________________________________________
CNF_16lyrs_20_20_shape_100k2Zee_0.05_060324.pt
trained for 20 epochs

final loss = 0.13212835788726807

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[1.3126596212387085, 1.050322413444519, 0.837563157081604, 0.7036973834037781, 0.5588464140892029, 0.45667266845703125, 0.382991760969162, 0.34499362111091614, 0.29772424697875977, 0.2711435854434967, 0.24037621915340424, 0.2128312587738037, 0.2131674736738205, 0.1902681440114975, 0.19587136805057526, 0.1930108219385147, 0.18640249967575073, 0.17586944997310638, 0.17987942695617676, 0.1685677021741867, 0.1644679307937622, 0.16233913600444794, 0.16072513163089752, 0.1624547243118286, 0.14997689425945282, 0.14533208310604095, 0.15280529856681824, 0.14374473690986633, 0.14329363405704498, 0.1539294570684433, 0.1376325637102127, 0.14889004826545715, 0.12977783381938934, 0.14601628482341766, 0.13491399586200714, 0.13369077444076538, 0.13378463685512543, 0.12695366144180298, 0.1344609260559082, 0.12867353856563568]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[0.8531545996665955, 0.8500873446464539, 0.5779744982719421, 0.5649714469909668, 0.39518529176712036, 0.3013225495815277, 0.2994094789028168, 0.24732349812984467, 0.2377372831106186, 0.20483659207820892, 0.19450880587100983, 0.19171065092086792, 0.19951556622982025, 0.19681653380393982, 0.18436969816684723, 0.18568767607212067, 0.1631011813879013, 0.16533605754375458, 0.16785795986652374, 0.15504895150661469, 0.1464303582906723, 0.15092746913433075, 0.14964236319065094, 0.14298050105571747, 0.1510728895664215, 0.1443966180086136, 0.14289121329784393, 0.1317819356918335, 0.1324264407157898, 0.13605836033821106, 0.13150660693645477, 0.1302710771560669, 0.13508369028568268, 0.13212835788726807]

____________________________________________________
CNF_32lyrs_10_10_shape_100k2Zee_0.05_060324.pt
trained for 19 epochs

index : 9

final loss = 0.14668916165828705

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[3.5352065563201904, 3.0617213249206543, 2.6789839267730713, 2.35345721244812, 2.0553483963012695, 1.7875365018844604, 1.5340299606323242, 1.2902432680130005, 1.0752754211425781, 0.8972324728965759, 0.7527925968170166, 0.6303386092185974, 0.5515949130058289, 0.4730716645717621, 0.42213067412376404, 0.3764915466308594, 0.33214157819747925, 0.3097003400325775, 0.2860189378261566, 0.26899096369743347, 0.24137890338897705, 0.21634523570537567, 0.2168060839176178, 0.20568852126598358, 0.20849823951721191, 0.19415222108364105, 0.18977336585521698, 0.1814584732055664, 0.18004249036312103, 0.17169128358364105, 0.16771411895751953, 0.16773664951324463, 0.16277894377708435, 0.16587017476558685, 0.1612986922264099, 0.15267035365104675, 0.15684138238430023, 0.1572532057762146]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[2.6936604976654053, 2.6778295040130615, 2.0603647232055664, 2.0585451126098633, 1.537099838256836, 1.085348129272461, 1.0867464542388916, 0.7565513253211975, 0.7566502690315247, 0.5447668433189392, 0.42706751823425293, 0.4225786328315735, 0.34357187151908875, 0.34139007329940796, 0.2929278016090393, 0.23938076198101044, 0.24709010124206543, 0.22379396855831146, 0.20803327858448029, 0.1946176439523697, 0.1959599107503891, 0.19075091183185577, 0.181767076253891, 0.1866237074136734, 0.17078448832035065, 0.1660291850566864, 0.16722650825977325, 0.16186027228832245, 0.15536688268184662, 0.1545754224061966, 0.15154725313186646, 0.1513163298368454]

____________________________________________________
CNF_32lyrs_20_20_shape_100k2Zee_0.05_060324.pt
trained for 19 epochs

index : 10

final loss = 0.12404458969831467

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[2.6323773860931396, 1.9625147581100464, 1.4793782234191895, 1.1296098232269287, 0.8118492960929871, 0.6138483285903931, 0.4675731658935547, 0.3819552958011627, 0.32725587487220764, 0.28476259112358093, 0.25610753893852234, 0.23488135635852814, 0.20457375049591064, 0.19653041660785675, 0.1864059418439865, 0.18135394155979156, 0.16301541030406952, 0.15369266271591187, 0.16178975999355316, 0.1525498777627945, 0.15253229439258575, 0.15187714993953705, 0.14601938426494598, 0.14361488819122314, 0.13834398984909058, 0.14020676910877228, 0.13720382750034332, 0.132070854306221, 0.13335049152374268, 0.13688714802265167, 0.13636089861392975, 0.12773831188678741, 0.12887123227119446, 0.12569205462932587, 0.12287142127752304, 0.1306968778371811, 0.13313840329647064, 0.12622083723545074]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[1.4800519943237305, 1.4719260931015015, 0.8090967535972595, 0.8208773732185364, 0.4674825370311737, 0.32637259364128113, 0.32979413866996765, 0.24535027146339417, 0.25618597865104675, 0.21772824227809906, 0.20053091645240784, 0.19940301775932312, 0.1685025691986084, 0.16933633387088776, 0.1591084599494934, 0.15436337888240814, 0.1574987918138504, 0.15550974011421204, 0.13786862790584564, 0.13866059482097626, 0.1423533856868744, 0.13615749776363373, 0.1397891640663147, 0.12994280457496643, 0.1285737305879593, 0.1269369125366211, 0.1378476768732071, 0.12814946472644806, 0.1264449506998062, 0.12923666834831238, 0.1191583052277565, 0.12643994390964508]

____________________________________________________
CNF_32lyrs_40_40_shape_100k2Zee_0.05_060324.pt
trained for 19 epochs

index : 11

final loss = 0.112181656062603

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[2.004753828048706, 1.0009180307388306, 0.4783998429775238, 0.3124274015426636, 0.25188401341438293, 0.22650010883808136, 0.19521495699882507, 0.1772010773420334, 0.16925115883350372, 0.1615925282239914, 0.15937326848506927, 0.14798597991466522, 0.15162204205989838, 0.14232520759105682, 0.14608274400234222, 0.1397736370563507, 0.1355161815881729, 0.1404021680355072, 0.13404463231563568, 0.13647933304309845, 0.1288476586341858, 0.1299123913049698, 0.12243226915597916, 0.12125829607248306, 0.12414522469043732, 0.12326119095087051, 0.11912962049245834, 0.11443227529525757, 0.11571384966373444, 0.1180984154343605, 0.11524422466754913, 0.1170797273516655, 0.11306089162826538, 0.11460631340742111, 0.11826670169830322, 0.11218048632144928, 0.11919849365949631, 0.10966359823942184]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[0.48715636134147644, 0.4857151508331299, 0.24288761615753174, 0.2379419356584549, 0.18900567293167114, 0.1583782285451889, 0.16707447171211243, 0.14845503866672516, 0.1554519087076187, 0.15290935337543488, 0.145284965634346, 0.14025862514972687, 0.13493287563323975, 0.14332300424575806, 0.12638422846794128, 0.12144434452056885, 0.12461855262517929, 0.11650265753269196, 0.12381140142679214, 0.12198760360479355, 0.11571305990219116, 0.12355943024158478, 0.11885837465524673, 0.11274241656064987, 0.11126772314310074, 0.1109541580080986, 0.11344867199659348, 0.1120622530579567, 0.11156146973371506, 0.11128208786249161, 0.11004605144262314, 0.11410530656576157]

____________________________________________________
CNF_32lyrs_80_80_shape_100k2Zee_0.05_060324.pt
trained for 19 epochs

index : 12

final loss = 0.1174754872918129

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[1.5930222272872925, 0.32772693037986755, 0.23510561883449554, 0.19706150889396667, 0.16460320353507996, 0.15811625123023987, 0.14872528612613678, 0.14182689785957336, 0.13590548932552338, 0.12597724795341492, 0.1282937377691269, 0.13220183551311493, 0.12161079794168472, 0.1220700740814209, 0.11424865573644638, 0.11786884069442749, 0.11741624027490616, 0.11190048605203629, 0.11368822306394577, 0.11116732656955719, 0.11342131346464157, 0.11443241685628891, 0.11614657938480377, 0.10919051617383957, 0.11451975256204605, 0.11175835132598877, 0.10589921474456787, 0.10736560821533203, 0.10377667099237442, 0.11027193069458008, 0.108734130859375, 0.10844283550977707, 0.11213818937540054, 0.10524354130029678, 0.10578680038452148, 0.10907147079706192, 0.1057906523346901, 0.11219476908445358]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[0.23591963946819305, 0.2350577861070633, 0.16750775277614594, 0.17838741838932037, 0.15756893157958984, 0.13259553909301758, 0.14377985894680023, 0.1279905140399933, 0.13301607966423035, 0.12185110151767731, 0.12458493560552597, 0.1238284632563591, 0.11758636683225632, 0.12316310405731201, 0.12048860639333725, 0.12022532522678375, 0.11382788419723511, 0.11667471379041672, 0.11152461916208267, 0.11778173595666885, 0.11428271979093552, 0.11196696758270264, 0.11137644201517105, 0.1184898167848587, 0.11231976002454758, 0.10873625427484512, 0.1127985343337059, 0.10904254764318466, 0.11640995740890503, 0.11393555253744125, 0.10977121442556381, 0.11212065070867538]

____________________________________________________
CNF_32lyrs_10_10_10_shape_100k2Zee_0.05_060324.pt
trained for 19 epochs

index : 13

final loss = 0.16033367812633514

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[3.0556070804595947, 2.7310569286346436, 2.438016653060913, 2.1638641357421875, 1.8995832204818726, 1.6556261777877808, 1.4036016464233398, 1.16645348072052, 0.9591582417488098, 0.7864933013916016, 0.6566030383110046, 0.5851979851722717, 0.5105780363082886, 0.46709737181663513, 0.419875830411911, 0.3993493318557739, 0.37456002831459045, 0.3720878064632416, 0.3246926963329315, 0.2855786681175232, 0.27212971448898315, 0.27034828066825867, 0.24037061631679535, 0.23634865880012512, 0.22941648960113525, 0.22279684245586395, 0.21038579940795898, 0.20790715515613556, 0.18613819777965546, 0.19687150418758392, 0.19518953561782837, 0.17761044204235077, 0.18743781745433807, 0.17323265969753265, 0.1703989952802658, 0.16082434356212616, 0.16754871606826782, 0.16608701646327972]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[2.4358370304107666, 2.437302350997925, 1.9210408926010132, 1.900183916091919, 1.4313127994537354, 0.9541897773742676, 0.9579378962516785, 0.6577447652816772, 0.6611201763153076, 0.6581634283065796, 0.4350351393222809, 0.4373845160007477, 0.36887073516845703, 0.37132471799850464, 0.33362269401550293, 0.2967035472393036, 0.48533302545547485, 0.49082013964653015, 0.24806120991706848, 0.23185335099697113, 0.4415378272533417, 0.20138144493103027, 0.1951766312122345, 0.20497547090053558, 0.20185230672359467, 0.18813611567020416, 0.1744059920310974, 0.18598099052906036, 0.17323395609855652, 0.1626557558774948, 0.16483795642852783, 0.3543393313884735]

____________________________________________________
CNF_32lyrs_80_80_80_shape_100k2Zee_0.05_060324.pt
trained for 19 epochs

index : 14

final loss = 0.10610928386449814

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[1.2054580450057983, 0.30607131123542786, 0.21187882125377655, 0.20044825971126556, 0.17362429201602936, 0.15117914974689484, 0.1458464413881302, 0.14887838065624237, 0.13646511733531952, 0.13015185296535492, 0.12332234531641006, 0.12437007576227188, 0.11987433582544327, 0.1137050911784172, 0.11423758417367935, 0.1166292056441307, 0.11321582645177841, 0.10752793401479721, 0.10998332500457764, 0.1058327779173851, 0.11189129203557968, 0.11304666101932526, 0.11206716299057007, 0.10826792567968369, 0.10954749584197998, 0.10644251108169556, 0.1068018227815628, 0.10649937391281128, 0.11081605404615402, 0.1053059846162796, 0.10577882826328278, 0.10572802275419235, 0.10776921361684799, 0.11005786806344986, 0.10164473205804825, 0.10551968961954117, 0.1065073236823082, 0.1028071865439415]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[0.2220572531223297, 0.3886602222919464, 0.1754186600446701, 0.1731857806444168, 0.1442999392747879, 0.13029029965400696, 0.13414771854877472, 0.12846636772155762, 0.12026307731866837, 0.11390908062458038, 0.32034146785736084, 0.11941772699356079, 0.11720295250415802, 0.3585565388202667, 0.11445269733667374, 0.11153342574834824, 0.3294568955898285, 0.3285432755947113, 0.11053593456745148, 0.10823805630207062, 0.11067434400320053, 0.11518831551074982, 0.1032310351729393, 0.1123860627412796, 0.3295448422431946, 0.333668977022171, 0.10288511961698532, 0.10656038671731949, 0.11025384813547134, 0.10531961172819138, 0.3308742344379425, 0.10755564272403717]

____________________________________________________
CNF_32lyrs_20_20_20_20_shape_100k2Zee_0.05_060324.pt
trained for 19 epochs

index : 15

final loss = 0.11745412647724152

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[2.254805326461792, 1.8027559518814087, 1.4131685495376587, 1.0543574094772339, 0.7656034827232361, 0.5562168955802917, 0.4206788241863251, 0.3414445221424103, 0.29227665066719055, 0.27348068356513977, 0.235499307513237, 0.24016503989696503, 0.21567165851593018, 0.21648721396923065, 0.21483290195465088, 0.21143248677253723, 0.1902739405632019, 0.19415844976902008, 0.17761139571666718, 0.1733940988779068, 0.16611646115779877, 0.16859623789787292, 0.1560753881931305, 0.16192202270030975, 0.14931194484233856, 0.1554916650056839, 0.13957703113555908, 0.13498853147029877, 0.145923912525177, 0.149237722158432, 0.1337573528289795, 0.1328006535768509, 0.12601590156555176, 0.1340389996767044, 0.12761996686458588, 0.12567071616649628, 0.1340608447790146, 0.1278015524148941]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[1.412152647972107, 1.4154424667358398, 0.7647251486778259, 0.7586928606033325, 0.4346875250339508, 0.28099700808525085, 0.47429952025413513, 0.33806005120277405, 0.2367469072341919, 0.23282721638679504, 0.23257692158222198, 0.21322162449359894, 0.20917944610118866, 0.2140452116727829, 0.17746680974960327, 0.16888585686683655, 0.1836862862110138, 0.1622963398694992, 0.15704697370529175, 0.15543103218078613, 0.15879926085472107, 0.14462950825691223, 0.16416458785533905, 0.14607517421245575, 0.15889374911785126, 0.13014666736125946, 0.16779755055904388, 0.16275684535503387, 0.1253018081188202, 0.1245759129524231, 0.13251832127571106, 0.12704914808273315]

____________________________________________________
CNF_64lyrs_20_20_shape_100k2Zee_0.05_060324.pt
trained for 19 epochs

final loss = 0.12075629085302353

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[5.118491172790527, 3.816488742828369, 2.8291471004486084, 2.035933256149292, 1.3983405828475952, 0.9643204808235168, 0.6841534972190857, 0.48100313544273376, 0.3709138035774231, 0.31134724617004395, 0.26177293062210083, 0.2338443547487259, 0.2258100062608719, 0.20519141852855682, 0.18975242972373962, 0.1829109936952591, 0.16870105266571045, 0.16428236663341522, 0.155155748128891, 0.14766786992549896, 0.14193712174892426, 0.1492418348789215, 0.14516976475715637, 0.14484280347824097, 0.14544788002967834, 0.1329769641160965, 0.13078822195529938, 0.13090310990810394, 0.1271788328886032, 0.12122993916273117, 0.12462814897298813, 0.12038445472717285, 0.12531158328056335, 0.11261140555143356, 0.12084310501813889, 0.11337389051914215, 0.1203097328543663, 0.12224481254816055]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[2.831692695617676, 2.8309853076934814, 1.409052848815918, 1.4051603078842163, 0.6687098145484924, 0.37663933634757996, 0.3724856674671173, 0.27215343713760376, 0.2618640959262848, 0.2207907885313034, 0.18588821589946747, 0.1959926337003708, 0.1778925657272339, 0.17209061980247498, 0.15564441680908203, 0.15243443846702576, 0.14369086921215057, 0.13981576263904572, 0.13868366181850433, 0.13789303600788116, 0.13473163545131683, 0.1376674622297287, 0.13319483399391174, 0.12697945535182953, 0.127369686961174, 0.12573407590389252, 0.12723477184772491, 0.12224715203046799, 0.12590350210666656, 0.1204049214720726, 0.1167556643486023, 0.11754713207483292]

____________________________________________________
CNF_128lyrs_20_20_shape_100k2Zee_0.05_060324.pt
trained for 17 epochs

final loss = 0.11267708986997604

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[10.111177444458008, 7.4390130043029785, 5.205064296722412, 3.4418869018554688, 2.241199254989624, 1.494659662246704, 1.0544780492782593, 0.7789464592933655, 0.60902339220047, 0.487169474363327, 0.40564703941345215, 0.340650737285614, 0.3026212751865387, 0.27549394965171814, 0.25367212295532227, 0.22706130146980286, 0.20698444545269012, 0.17891943454742432, 0.17915832996368408, 0.1591169685125351, 0.15494441986083984, 0.14683856070041656, 0.13420172035694122, 0.13819752633571625, 0.12380639463663101, 0.13400037586688995, 0.13320301473140717, 0.12486016750335693, 0.1282222718000412, 0.12434463948011398, 0.12347512692213058, 0.11278941482305527, 0.11895795911550522, 0.11488360166549683]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[5.2037672996521, 5.205156326293945, 2.2350802421569824, 2.231919050216675, 1.0470227003097534, 0.5971652865409851, 0.6136586666107178, 0.41415277123451233, 0.41264697909355164, 0.3004591464996338, 0.24941547214984894, 0.25088775157928467, 0.205539733171463, 0.2075892984867096, 0.17756445705890656, 0.15181276202201843, 0.15002655982971191, 0.12960609793663025, 0.13414515554904938, 0.12603388726711273, 0.12724336981773376, 0.12404324114322662, 0.12201594561338425, 0.1202838197350502, 0.1146872416138649, 0.1189894825220108, 0.11717001348733902, 0.11704857647418976, 0.11267708986997604]

____________________________________________________
CNF_256lyrs_10_10_shape_100k2Zee_0.05_060324.pt
trained for 15 epochs

index : 18

final loss = 0.4587268829345703

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[24.16425132751465, 20.930343627929688, 17.929954528808594, 15.147311210632324, 12.554065704345703, 10.085792541503906, 7.901641368865967, 6.096378326416016, 4.678042888641357, 3.6726150512695312, 2.9714889526367188, 2.5008533000946045, 2.173365354537964, 1.9269369840621948, 1.720202088356018, 1.5579043626785278, 1.430284023284912, 1.3120402097702026, 1.2128139734268188, 1.128434419631958, 1.0475062131881714, 0.972529411315918, 0.9079872369766235, 0.8420054316520691, 0.7815855145454407, 0.7157245874404907, 0.660758912563324, 0.6019794344902039, 0.5532893538475037, 0.5052581429481506]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[17.945926666259766, 17.939115524291992, 12.550883293151855, 12.556647300720215, 7.909008026123047, 4.673893451690674, 4.678346157073975, 2.9765069484710693, 2.9706010818481445, 2.174820899963379, 1.7151224613189697, 1.7155011892318726, 1.4276762008666992, 1.4225066900253296, 1.211809754371643, 1.0452581644058228, 1.0436493158340454, 0.9013509154319763, 0.9067657589912415, 0.7834283113479614, 0.6678398847579956, 0.6618549227714539, 0.5528832674026489, 0.5437846183776855, 0.4539510905742645]

____________________________________________________
CNF_256lyrs_20_20_shape_100k2Zee_0.05_060324.pt
trained for 15 epochs

index : 19

final loss = 0.11747708171606064

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[18.71529769897461, 13.298762321472168, 8.961061477661133, 5.532229900360107, 3.2761268615722656, 2.0713281631469727, 1.4825280904769897, 1.1296589374542236, 0.881752610206604, 0.7314762473106384, 0.634435772895813, 0.55437171459198, 0.48676133155822754, 0.41068345308303833, 0.3438020348548889, 0.30747824907302856, 0.2753269672393799, 0.260227769613266, 0.24186530709266663, 0.22683273255825043, 0.21601830422878265, 0.18653692305088043, 0.17551873624324799, 0.14801038801670074, 0.13754083216190338, 0.1322927325963974, 0.1252899169921875, 0.1249750480055809, 0.12191849201917648, 0.11261530965566635]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[8.979571342468262, 8.989694595336914, 3.2716939449310303, 3.2715282440185547, 1.4885261058807373, 0.8790898323059082, 0.8815967440605164, 0.629240870475769, 0.6374449133872986, 0.4791129529476166, 0.3427821099758148, 0.35058078169822693, 0.27948567271232605, 0.2770412266254425, 0.24218058586120605, 0.20916007459163666, 0.2085805982351303, 0.17058084905147552, 0.16789501905441284, 0.13510696589946747, 0.12448374181985855, 0.12278838455677032, 0.11958885192871094, 0.12320884317159653, 0.11164776235818863]

____________________________________________________
CNF_256lyrs_40_40_shape_100k2Zee_0.05_060324.pt
trained for 15 epochs

index : 20

final loss = 0.11147699505090714

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[15.391105651855469, 6.751256465911865, 2.45853853225708, 0.9930395483970642, 0.5397382378578186, 0.3169100284576416, 0.210104301571846, 0.17451529204845428, 0.14774136245250702, 0.1384209245443344, 0.14077551662921906, 0.13302041590213776, 0.13258753716945648, 0.1243417039513588, 0.13213257491588593, 0.12248214334249496, 0.12436143308877945, 0.1231062188744545, 0.12041383981704712, 0.11650308221578598, 0.1107485219836235, 0.11872749775648117, 0.113167904317379, 0.1119111180305481, 0.11516972631216049, 0.11095818132162094, 0.11032146215438843, 0.11438614130020142, 0.10770179331302643, 0.10962603241205215]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[2.4489858150482178, 2.4584755897521973, 0.5388600826263428, 0.5373896956443787, 0.20459365844726562, 0.14658424258232117, 0.14403550326824188, 0.1358114331960678, 0.1362810730934143, 0.13031260669231415, 0.13266628980636597, 0.1261415183544159, 0.1262156367301941, 0.12429165095090866, 0.12598323822021484, 0.10882029682397842, 0.11977147310972214, 0.10845400393009186, 0.11350639164447784, 0.11298525333404541, 0.1147804856300354, 0.11099475622177124, 0.11652693897485733, 0.10996421426534653, 0.10773231089115143]

____________________________________________________
CNF_256lyrs_80_80_shape_100k2Zee_0.05_060324.pt
trained for 15 epochs

index : 21

final loss = 0.11060459911823273

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[13.44359302520752, 1.276160478591919, 0.2865855395793915, 0.1888459175825119, 0.1585869938135147, 0.12978500127792358, 0.127982497215271, 0.12834109365940094, 0.1179889664053917, 0.12406881898641586, 0.11605963855981827, 0.11241381615400314, 0.11068738996982574, 0.11234994977712631, 0.10883104056119919, 0.112271748483181, 0.10756828635931015, 0.11403883993625641, 0.10412585735321045, 0.10988640785217285, 0.11122039705514908, 0.11251919716596603, 0.1092066690325737, 0.10745912045240402, 0.10924295336008072, 0.10784383118152618, 0.1060578003525734, 0.10799681395292282, 0.10131650418043137, 0.11202781647443771]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[0.29062148928642273, 0.2697913944721222, 0.16250209510326385, 0.1531222015619278, 0.13066941499710083, 0.1956222504377365, 0.12182481586933136, 0.11619068682193756, 0.11350011080503464, 0.11201450973749161, 0.11720984429121017, 0.3240233361721039, 0.2965429723262787, 0.11721570789813995, 0.29601338505744934, 0.10784395039081573, 0.27744174003601074, 0.233851358294487, 0.10999292135238647, 0.21196208894252777, 0.10469891130924225, 0.11022781580686569, 0.10671279579401016, 0.10794539749622345, 0.18241046369075775]

____________________________________________________
CNF_256lyrs_10_10_10_shape_100k2Zee_0.05_060324.pt
trained for 15 epochs

index : 22

final loss = 0.4457975924015045

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[22.122770309448242, 19.66021728515625, 17.28122901916504, 14.866029739379883, 12.420836448669434, 10.105575561523438, 8.022425651550293, 6.344703197479248, 5.044591426849365, 4.099629878997803, 3.4497947692871094, 2.994070053100586, 2.6390960216522217, 2.350019693374634, 2.093014717102051, 1.8623632192611694, 1.6778805255889893, 1.5193403959274292, 1.385018229484558, 1.2625459432601929, 1.1360214948654175, 1.025575876235962, 0.9273815155029297, 0.827404797077179, 0.740566611289978, 0.6876251101493835, 0.6264796257019043, 0.5820135474205017, 0.5401391386985779, 0.4924100935459137]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[17.278133392333984, 17.280868530273438, 12.421954154968262, 12.425236701965332, 8.019749641418457, 5.042039394378662, 5.0455732345581055, 3.4506490230560303, 3.44907808303833, 2.6409149169921875, 2.0883045196533203, 2.095174551010132, 1.6754038333892822, 1.6813230514526367, 1.3936570882797241, 1.1420553922653198, 1.1358598470687866, 0.9372464418411255, 0.9280261993408203, 0.7544379234313965, 0.6238798499107361, 0.6292361617088318, 0.546735405921936, 0.5386373400688171, 0.44359779357910156]

____________________________________________________
CNF_256lyrs_80_80_80_shape_100k2Zee_0.05_060324.pt
trained for 15 epochs

index : 23

final loss = 0.1130913719534874

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[8.813519477844238, 0.8908055424690247, 0.2508007287979126, 0.18518167734146118, 0.15719372034072876, 0.15181805193424225, 0.14514152705669403, 0.1334041804075241, 0.13389702141284943, 0.12740610539913177, 0.1233549490571022, 0.12218587845563889, 0.11268875747919083, 0.11166834086179733, 0.10949122160673141, 0.1065378189086914, 0.10485624521970749, 0.10653616487979889, 0.10915561020374298, 0.11086452007293701, 0.10701626539230347, 0.10722409933805466, 0.10450464487075806, 0.10845144093036652, 0.10396083444356918, 0.10303603857755661, 0.10654234141111374, 0.10901430994272232, 0.10378538817167282, 0.10230707377195358]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[0.2672325372695923, 0.2674711048603058, 0.15961210429668427, 0.16684159636497498, 0.15645243227481842, 0.14109843969345093, 0.1445251852273941, 0.12363149970769882, 0.13412170112133026, 0.11693151295185089, 0.11489995568990707, 0.11015408486127853, 0.11347061395645142, 0.11445128917694092, 0.1149735376238823, 0.11077268421649933, 0.10842591524124146, 0.11007368564605713, 0.10823973268270493, 0.10803856700658798, 0.10880845785140991, 0.10762007534503937, 0.10676243156194687, 0.11069779843091965, 0.10955630987882614]

____________________________________________________
CNF_256lyrs_20_20_20_20_shape_100k2Zee_0.05_060324.pt
trained for 15 epochs

index : 24

final loss = 0.20678602159023285

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[15.867738723754883, 12.463868141174316, 9.08689022064209, 5.987096309661865, 3.9416797161102295, 2.819218158721924, 2.138484477996826, 1.6642427444458008, 1.3251229524612427, 1.0436218976974487, 0.7964134216308594, 0.6198891997337341, 0.5352796912193298, 0.4809044897556305, 0.4326459467411041, 0.3956380784511566, 0.3764081597328186, 0.3666961193084717, 0.34268149733543396, 0.3293280005455017, 0.3124225437641144, 0.2990991175174713, 0.28603649139404297, 0.2668958604335785, 0.24552969634532928, 0.2175656408071518, 0.18047890067100525, 0.1434299200773239, 0.12422716617584229, 0.1237078458070755]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[9.086878776550293, 9.089945793151855, 3.942584753036499, 3.942767381668091, 2.137385606765747, 1.3257372379302979, 1.3300657272338867, 0.8098875880241394, 0.8010885119438171, 0.5422800183296204, 0.43260103464126587, 0.43469515442848206, 0.3784539997577667, 0.4247800409793854, 0.34330853819847107, 0.320693701505661, 0.3208947777748108, 0.2801404297351837, 0.36919301748275757, 0.2399987280368805, 0.18051019310951233, 0.22480659186840057, 0.1349474936723709, 0.18211466073989868, 0.12325101345777512]

____________________________________________________
CNF_512lyrs_20_20_shape_100k2Zee_0.05_060324.pt
trained for 10 epochs

final loss = 0.29038476943969727

training loss exerpt (in steps of 10 to reduce amount of data displayed) :
[36.8502311706543, 26.400075912475586, 18.00874137878418, 11.253230094909668, 6.438199520111084, 3.6065967082977295, 2.2203786373138428, 1.5664558410644531, 1.2254217863082886, 0.9997332692146301, 0.8152870535850525, 0.6584898829460144, 0.5517184138298035, 0.4826555848121643, 0.44474321603775024, 0.4136158525943756, 0.3950381577014923, 0.37087205052375793, 0.34502315521240234, 0.3205987513065338]

testing loss exerpt (in steps of 3 to reduce amount of data displayed) :
[18.002925872802734, 17.99733543395996, 6.421205997467041, 6.436517238616943, 2.2027692794799805, 1.226467490196228, 1.2183539867401123, 0.8116188049316406, 0.8061451315879822, 0.5365576148033142, 0.4390315115451813, 0.42738768458366394, 0.383797824382782, 0.3904266953468323, 0.34394028782844543, 0.29453539848327637, 0.2883225381374359]

____________________________________________________

 successfuly exited full training and testing loop

final testing errors, ordered by model index :
[0.19563519954681396, 0.16536399722099304, 0.13069355487823486, 0.11691804230213165, 0.19735847413539886, 0.11389028280973434, 0.1856699436903, 0.15046517550945282, 0.13212835788726807, 0.14668916165828705, 0.12404458969831467, 0.112181656062603, 0.1174754872918129, 0.16033367812633514, 0.10610928386449814, 0.11745412647724152, 0.12075629085302353, 0.11267708986997604, 0.4587268829345703, 0.11747708171606064, 0.11147699505090714, 0.11060459911823273, 0.4457975924015045, 0.1130913719534874, 0.20678602159023285, 0.29038476943969727]